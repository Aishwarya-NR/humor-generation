{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import importlib\n",
    "from library import data_preprocess as dp\n",
    "importlib.reload(dp)\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Embedding, TimeDistributed, Flatten, Merge, Concatenate\n",
    "from keras import regularizers\n",
    "from keras.metrics import sparse_categorical_accuracy, sparse_categorical_crossentropy\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://nlp.stanford.edu/data/glove.6B.zip\n",
    "DATA_PATH = './datasets/combined.pickle'\n",
    "VOCAB_PATH = './datasets/combined_vocabulary.pickle'\n",
    "MODELS_PATH = './models/'\n",
    "\n",
    "GLOVE_PATH = './data/glove/glove.6B.200d.txt'\n",
    "\n",
    "MODEL_PREFIX = 'combined_jokes_quote_controlled_stacked_lstm_glove'\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 13\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "GLOVE_EMBEDDING_DIM = 200\n",
    "EMBEDDING_DIM1 = 512\n",
    "EMBEDDING_DIM2 = 512\n",
    "HIDDEN_DIM1 = 1024\n",
    "HIDDEN_DIM2 = 512\n",
    "DEEPER_DIM = 512\n",
    "DROPOUT_FACTOR = 0.2\n",
    "REGULARIZATION = 0.00001\n",
    "LEARNING_RATE = 0.003\n",
    "\n",
    "DATA_PERCENT = 0.1\n",
    "\n",
    "RUN_INDEX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences =  140293\n",
      "[[0, 'sos the lady at the bakery who draws her eyebrows on is looking extra surprised today eos'], [0, 'sos do you know why one side of the v is slightly larger when birds fly together ? because there are more birds on that side . eos']]\n",
      "Vocab size =  12614\n",
      "['liberate', 'savings', 'clip', 'rhino', 'cross', 'encouragement', 'viewed', 'womens', 'lap', 'challenges']\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_PATH, 'rb') as pickleFile:\n",
    "    sentences = pickle.load(pickleFile)\n",
    "sentences = [sentence for sentence in sentences if sentence[0] != 2]\n",
    "with open(VOCAB_PATH, 'rb') as pickleFile:\n",
    "    vocab = pickle.load(pickleFile)\n",
    "    \n",
    "random.shuffle(sentences)\n",
    "\n",
    "print(\"Number of sentences = \", len(sentences))\n",
    "print(sentences[:2])\n",
    "print(\"Vocab size = \", len(vocab))\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jokes:  96910\n",
      "Number of Quotes:  43383\n",
      "JOKES_WEIGHT:  1.4476627798988753\n",
      "QUOTES_WEIGHT:  3.233824309061153\n"
     ]
    }
   ],
   "source": [
    "NUM_JOKES = len([0 for item in sentences if item[0] == 0])\n",
    "NUM_QUOTES = len([1 for item in sentences if item[0] == 1])\n",
    "#NUM_TWEETS = len([2 for item in sentences if item[0] == 2])\n",
    "print(\"Number of Jokes: \", NUM_JOKES)\n",
    "print(\"Number of Quotes: \", NUM_QUOTES)\n",
    "#print(\"Number of Tweets: \", NUM_TWEETS)\n",
    "TOTAL_SENTENCES = NUM_JOKES + NUM_QUOTES\n",
    "JOKES_WEIGHT = TOTAL_SENTENCES/NUM_JOKES\n",
    "QUOTES_WEIGHT = TOTAL_SENTENCES/NUM_QUOTES\n",
    "#TWEETS_WEIGHT = TOTAL_SENTENCES/NUM_TWEETS\n",
    "print(\"JOKES_WEIGHT: \", JOKES_WEIGHT)\n",
    "print(\"QUOTES_WEIGHT: \", QUOTES_WEIGHT)\n",
    "#print(\"TWEETS_WEIGHT: \", TWEETS_WEIGHT)\n",
    "\n",
    "CLASS_WEIGHTS = [JOKES_WEIGHT, QUOTES_WEIGHT]\n",
    "CLASSES = [item[0] for item in sentences]\n",
    "sentences = [item[1] for item in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 797, 39, 4, 4094, 70, 7971, 85, 3415, 26, 12, 271, 1371, 1508, 80, 2], [1, 24, 11, 66, 46, 53, 433, 14, 4, 3242, 12, 2616, 3441, 38, 1706, 750, 474, 10, 61, 74, 35, 94, 1706, 26, 20, 433, 3, 2], [1, 285, 8, 100, 4, 174, 314, 2848, 162, 11, 66, 10, 2], [1, 1716, 12, 129, 1308, 7, 1553, 21, 4, 5468, 11, 3661, 420, 3, 2], [1, 1075, 3533, 46, 24, 6048, 486, 1075, 3533, 10, 61, 4, 999, 3533, 35, 7, 242, 3, 2]]\n",
      "12615\n"
     ]
    }
   ],
   "source": [
    "# tokenize data\n",
    "num_words = len(vocab)\n",
    "\n",
    "with open(\"../combined_controlled_stacked_lstm_glove_tokenizer_1.pickle\",\"rb\") as fip:\n",
    "    tokenizer = pickle.load(fip)\n",
    "# tokenizer = Tokenizer(num_words=None, filters='', lower=True, split=' ', \n",
    "#                       char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "assert num_words == len(tokenizer.word_index)\n",
    "\n",
    "encoded_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "print(encoded_sentences[:5])\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open(MODELS_PATH + MODEL_PREFIX + '_tokenizer_' + str(RUN_INDEX) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training data size =  1398826\n",
      "Max seq len =  13\n",
      "(1398826, 13)\n",
      "[[  104    13  5908     3    32    65    15    27     5   970    86    54\n",
      "     34]\n",
      " [  235     6    62    20    19   554    14   529     8     3    19     6\n",
      "    213]\n",
      " [   92  2961    46    58  2096  1892     5    68    14   517     9  1358\n",
      "      3]\n",
      " [10117     4   698     8   628     8     9   134    37   129    14   384\n",
      "    104]\n",
      " [  111    17    15   855 12134     8     9   218  3910  4031    20    22\n",
      "    120]]\n",
      "(1398826, 13, 1)\n",
      "[[[   13]\n",
      "  [ 5908]\n",
      "  [    3]\n",
      "  [   32]\n",
      "  [   65]\n",
      "  [   15]\n",
      "  [   27]\n",
      "  [    5]\n",
      "  [  970]\n",
      "  [   86]\n",
      "  [   54]\n",
      "  [   34]\n",
      "  [  524]]\n",
      "\n",
      " [[    6]\n",
      "  [   62]\n",
      "  [   20]\n",
      "  [   19]\n",
      "  [  554]\n",
      "  [   14]\n",
      "  [  529]\n",
      "  [    8]\n",
      "  [    3]\n",
      "  [   19]\n",
      "  [    6]\n",
      "  [  213]\n",
      "  [    6]]\n",
      "\n",
      " [[ 2961]\n",
      "  [   46]\n",
      "  [   58]\n",
      "  [ 2096]\n",
      "  [ 1892]\n",
      "  [    5]\n",
      "  [   68]\n",
      "  [   14]\n",
      "  [  517]\n",
      "  [    9]\n",
      "  [ 1358]\n",
      "  [    3]\n",
      "  [   49]]\n",
      "\n",
      " [[    4]\n",
      "  [  698]\n",
      "  [    8]\n",
      "  [  628]\n",
      "  [    8]\n",
      "  [    9]\n",
      "  [  134]\n",
      "  [   37]\n",
      "  [  129]\n",
      "  [   14]\n",
      "  [  384]\n",
      "  [  104]\n",
      "  [ 8248]]\n",
      "\n",
      " [[   17]\n",
      "  [   15]\n",
      "  [  855]\n",
      "  [12134]\n",
      "  [    8]\n",
      "  [    9]\n",
      "  [  218]\n",
      "  [ 3910]\n",
      "  [ 4031]\n",
      "  [   20]\n",
      "  [   22]\n",
      "  [  120]\n",
      "  [ 5842]]]\n",
      "(1398826, 13, 2)\n",
      "[[[1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]]\n",
      "\n",
      " [[1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]]\n",
      "(1398826,)\n",
      "[1.44766278 1.44766278 3.23382431 3.23382431 3.23382431]\n"
     ]
    }
   ],
   "source": [
    "TAG_SIZE = 2\n",
    "X_data = []\n",
    "y_data = []\n",
    "tag_data = []\n",
    "weight_data = []\n",
    "\n",
    "for idx, sentence in enumerate(encoded_sentences):\n",
    "    l = len(sentence)\n",
    "    sliding_window_length = min(l-3, MAX_SEQUENCE_LENGTH)\n",
    "    step_size = 1\n",
    "    for i in range(0, l - sliding_window_length, step_size):\n",
    "        X_data.append(sentence[i:i+sliding_window_length])\n",
    "        y_data.append(sentence[i+1:i+sliding_window_length+1])\n",
    "        tag_data.append(CLASSES[idx])\n",
    "        weight_data.append(CLASS_WEIGHTS[CLASSES[idx]])\n",
    "        \n",
    "print(\"Total training data size = \", len(X_data))\n",
    "MAX_SEQ_LEN = max([len(seq) for seq in X_data])\n",
    "print(\"Max seq len = \", MAX_SEQ_LEN)\n",
    "\n",
    "X_data = pad_sequences(X_data, maxlen=MAX_SEQ_LEN, padding='pre')\n",
    "y_data = pad_sequences(y_data, maxlen=MAX_SEQ_LEN, padding='pre').reshape(-1, MAX_SEQ_LEN, 1)\n",
    "tag_data = to_categorical([[[tag]]*MAX_SEQ_LEN for tag in tag_data], TAG_SIZE)\n",
    "weight_data = np.array(weight_data).reshape(-1,)\n",
    "#y_data = np.array(y_data).reshape(-1,1)\n",
    "\n",
    "# shuffle\n",
    "perm = np.random.permutation(X_data.shape[0])\n",
    "X_data = X_data[perm]\n",
    "y_data = y_data[perm]\n",
    "tag_data = tag_data[perm]\n",
    "weight_data = weight_data[perm]\n",
    "print(X_data.shape)\n",
    "print(X_data[:5])\n",
    "print(y_data.shape)\n",
    "print(y_data[:5])\n",
    "print(tag_data.shape)\n",
    "print(tag_data[:5])\n",
    "print(weight_data.shape)\n",
    "print(weight_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing glove word vectors\n",
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Indexing glove word vectors')\n",
    "#Glove Vectors\n",
    "glove_embeddings_index = {}\n",
    "f = open(GLOVE_PATH)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    glove_embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Total %s word vectors.' % len(glove_embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing glove embedding matrix\n",
      "Null word embeddings: 298\n",
      "(12615, 200)\n"
     ]
    }
   ],
   "source": [
    "print('Preparing glove embedding matrix')\n",
    "glove_embedding_matrix = np.zeros((VOCAB_SIZE, GLOVE_EMBEDDING_DIM))\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    embedding_vector = glove_embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        glove_embedding_matrix[i] = embedding_vector\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(glove_embedding_matrix, axis=1) == 0))\n",
    "print(glove_embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import merge\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def make_parallel(model, gpu_count):\n",
    "    def get_slice(data, idx, parts):\n",
    "        shape = tf.shape(data)\n",
    "        size = tf.concat([ shape[:1] // parts, shape[1:] ],axis=0)\n",
    "        stride = tf.concat([ shape[:1] // parts, shape[1:]*0 ],axis=0)\n",
    "        start = stride * idx\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    outputs_all = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        outputs_all.append([])\n",
    "\n",
    "    #Place a copy of the model on each GPU, each getting a slice of the batch\n",
    "    for i in range(gpu_count):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('tower_%d' % i) as scope:\n",
    "\n",
    "                inputs = []\n",
    "                #Slice each input into a piece for processing on this GPU\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_n = Lambda(get_slice, output_shape=input_shape, arguments={'idx':i,'parts':gpu_count})(x)\n",
    "                    inputs.append(slice_n)                \n",
    "\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "                \n",
    "                #Save all the outputs for merging back together later\n",
    "                for l in range(len(outputs)):\n",
    "                    outputs_all[l].append(outputs[l])\n",
    "\n",
    "    # merge outputs on CPU\n",
    "    with tf.device('/cpu:0'):\n",
    "        merged = []\n",
    "        for outputs in outputs_all:\n",
    "            merged.append(merge(outputs, mode='concat', concat_axis=0))\n",
    "            \n",
    "        return Model(input=model.inputs, output=merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "def StackedLSTM(vocab_size, glove_embedding_dim, glove_embedding_matrix, embedding_dim1, embedding_dim2,\n",
    "           hidden_dim1, hidden_dim2, deeper_dim, max_seq_len, tag_size,\n",
    "           dropout_factor=0.5, regularization=0.00001, learning_rate=0.001):\n",
    "    \n",
    "    inputs = Input(shape=(None,))\n",
    "    tag_inputs = Input(shape=(None,tag_size))\n",
    "    \n",
    "    glove_embedding = Embedding(vocab_size, glove_embedding_dim, #input_length=max_seq_len,\n",
    "                                  weights=[glove_embedding_matrix],\n",
    "                                  mask_zero=True,trainable=False)(inputs)\n",
    "    \n",
    "    word_embedding = Embedding(vocab_size, embedding_dim1, #input_length=max_seq_len, \n",
    "                               mask_zero=True, embeddings_regularizer=regularizers.l2(regularization))(inputs)\n",
    "    \n",
    "    #tag_embedding = Embedding(tag_size, tag_size, embeddings_regularizer=regularizers.l2(regularization))(tag_inputs)\n",
    "    \n",
    "    concat_embeds = Concatenate(axis=-1)([glove_embedding, word_embedding, tag_inputs])\n",
    "    \n",
    "    final_embed = Dense(units=embedding_dim2, activation='tanh',\n",
    "                        kernel_regularizer=regularizers.l2(regularization))(concat_embeds)\n",
    "    \n",
    "    lstm1 = LSTM(hidden_dim1, activation='tanh', \n",
    "                   kernel_regularizer=regularizers.l2(regularization), \n",
    "                   recurrent_regularizer=regularizers.l2(regularization), #unroll=True, \n",
    "                   return_sequences = True, dropout=dropout_factor, recurrent_dropout=dropout_factor)(final_embed)\n",
    "    \n",
    "    lstm2 = LSTM(hidden_dim2, activation='tanh', \n",
    "                   kernel_regularizer=regularizers.l2(regularization), \n",
    "                   recurrent_regularizer=regularizers.l2(regularization), #unroll=True, \n",
    "                   return_sequences = True, dropout=dropout_factor, recurrent_dropout=dropout_factor)(lstm1)\n",
    "    \n",
    "    timedist_dropout = TimeDistributed(Dropout(dropout_factor))(lstm2)\n",
    "    \n",
    "    deep_dense = Dense(units=deeper_dim, activation='tanh', \n",
    "                       kernel_regularizer=regularizers.l2(regularization))(timedist_dropout)\n",
    "    \n",
    "    dropout_layer1 = Dropout(dropout_factor)(deep_dense)\n",
    "    \n",
    "    outputs = Dense(units=vocab_size, activation='softmax', \n",
    "                    kernel_regularizer=regularizers.l2(regularization))(dropout_layer1)\n",
    "    \n",
    "    model = Model(inputs=[inputs,tag_inputs], outputs=outputs)\n",
    "    #model = make_parallel(Model(inputs=[inputs,tag_inputs], outputs=outputs), 2)\n",
    "    #model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=[sparse_categorical_crossentropy, sparse_categorical_accuracy]#, sample_weight_mode='temporal'\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 200)    2523000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 512)    6458880     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 714)    0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 512)    366080      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 1024)   6295552     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, None, 512)    3147776     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 512)    0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 512)    262656      time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 512)    0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 12615)  6471495     dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,525,439\n",
      "Trainable params: 23,002,439\n",
      "Non-trainable params: 2,523,000\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "model = StackedLSTM(vocab_size=VOCAB_SIZE, glove_embedding_dim=GLOVE_EMBEDDING_DIM,\n",
    "                    glove_embedding_matrix=glove_embedding_matrix, \n",
    "                    embedding_dim1=EMBEDDING_DIM1, embedding_dim2=EMBEDDING_DIM2,\n",
    "                    hidden_dim1=HIDDEN_DIM1, hidden_dim2=HIDDEN_DIM2,\n",
    "                    deeper_dim=DEEPER_DIM, max_seq_len=MAX_SEQ_LEN, dropout_factor=DROPOUT_FACTOR, \n",
    "                    regularization=REGULARIZATION, learning_rate=LEARNING_RATE, tag_size=TAG_SIZE)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TB(TensorBoard):\n",
    "    def __init__(self, log_every=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.log_every = log_every\n",
    "        self.counter = 0\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.counter+=1\n",
    "        if self.counter%self.log_every==0:\n",
    "            for name, value in logs.items():\n",
    "                if name in ['batch', 'size']:\n",
    "                    continue\n",
    "                summary = tf.Summary()\n",
    "                summary_value = summary.value.add()\n",
    "                summary_value.simple_value = value.item()\n",
    "                summary_value.tag = name\n",
    "                self.writer.add_summary(summary, self.counter)\n",
    "            self.writer.flush()\n",
    "        \n",
    "        super().on_batch_end(batch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1119060 samples, validate on 279766 samples\n",
      "Epoch 1/10\n",
      "1119060/1119060 [==============================] - 1729s 2ms/step - loss: 12.4156 - sparse_categorical_crossentropy: 5.6320 - sparse_categorical_accuracy: 0.1177 - val_loss: 10.0010 - val_sparse_categorical_crossentropy: 4.3293 - val_sparse_categorical_accuracy: 0.2334\n",
      "\n",
      "Epoch 00001: saving model to ./models/checkpoints/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.01-10.00.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 10.00103, saving model to ./models/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.hdf5\n",
      "Epoch 2/10\n",
      "1119060/1119060 [==============================] - 1741s 2ms/step - loss: 9.9473 - sparse_categorical_crossentropy: 4.2412 - sparse_categorical_accuracy: 0.2399 - val_loss: 9.3605 - val_sparse_categorical_crossentropy: 3.9238 - val_sparse_categorical_accuracy: 0.2732\n",
      "\n",
      "Epoch 00002: saving model to ./models/checkpoints/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.02-9.36.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 10.00103 to 9.36054, saving model to ./models/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.hdf5\n",
      "Epoch 3/10\n",
      "1119060/1119060 [==============================] - 1746s 2ms/step - loss: 9.6563 - sparse_categorical_crossentropy: 4.0374 - sparse_categorical_accuracy: 0.2590 - val_loss: 9.1109 - val_sparse_categorical_crossentropy: 3.7672 - val_sparse_categorical_accuracy: 0.2899\n",
      "\n",
      "Epoch 00003: saving model to ./models/checkpoints/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.03-9.11.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.36054 to 9.11086, saving model to ./models/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.hdf5\n",
      "Epoch 4/10\n",
      "1119060/1119060 [==============================] - 1742s 2ms/step - loss: 9.5236 - sparse_categorical_crossentropy: 3.9438 - sparse_categorical_accuracy: 0.2684 - val_loss: 8.9582 - val_sparse_categorical_crossentropy: 3.6753 - val_sparse_categorical_accuracy: 0.3005\n",
      "\n",
      "Epoch 00004: saving model to ./models/checkpoints/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.04-8.96.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 9.11086 to 8.95820, saving model to ./models/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.hdf5\n",
      "Epoch 5/10\n",
      "1119060/1119060 [==============================] - 1745s 2ms/step - loss: 9.4390 - sparse_categorical_crossentropy: 3.8853 - sparse_categorical_accuracy: 0.2746 - val_loss: 8.8573 - val_sparse_categorical_crossentropy: 3.6163 - val_sparse_categorical_accuracy: 0.3074\n",
      "\n",
      "Epoch 00005: saving model to ./models/checkpoints/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.05-8.86.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 8.95820 to 8.85735, saving model to ./models/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.hdf5\n",
      "Epoch 6/10\n",
      "1119060/1119060 [==============================] - 1744s 2ms/step - loss: 9.3755 - sparse_categorical_crossentropy: 3.8426 - sparse_categorical_accuracy: 0.2791 - val_loss: 8.7734 - val_sparse_categorical_crossentropy: 3.5681 - val_sparse_categorical_accuracy: 0.3133\n",
      "\n",
      "Epoch 00006: saving model to ./models/checkpoints/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.06-8.77.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 8.85735 to 8.77336, saving model to ./models/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.hdf5\n",
      "Epoch 7/10\n",
      "1119060/1119060 [==============================] - 1740s 2ms/step - loss: 9.3285 - sparse_categorical_crossentropy: 3.8116 - sparse_categorical_accuracy: 0.2827 - val_loss: 8.7135 - val_sparse_categorical_crossentropy: 3.5333 - val_sparse_categorical_accuracy: 0.3178\n",
      "\n",
      "Epoch 00007: saving model to ./models/checkpoints/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.07-8.71.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 8.77336 to 8.71355, saving model to ./models/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.hdf5\n",
      "Epoch 8/10\n",
      "1119060/1119060 [==============================] - 3071s 3ms/step - loss: 9.2894 - sparse_categorical_crossentropy: 3.7860 - sparse_categorical_accuracy: 0.2857 - val_loss: 8.6552 - val_sparse_categorical_crossentropy: 3.5008 - val_sparse_categorical_accuracy: 0.3222\n",
      "\n",
      "Epoch 00008: saving model to ./models/checkpoints/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.08-8.66.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 8.71355 to 8.65516, saving model to ./models/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.hdf5\n",
      "Epoch 9/10\n",
      " 272384/1119060 [======>.......................] - ETA: 1:26:57 - loss: 9.2071 - sparse_categorical_crossentropy: 3.7483 - sparse_categorical_accuracy: 0.2894"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ded347e4311b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m model.fit([X_data, tag_data], y_data, epochs=10, batch_size=1024, shuffle=True, \n\u001b[0;32m---> 13\u001b[0;31m           verbose=1, validation_split=0.2, callbacks=callbacks, sample_weight=weight_data)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total elapsed time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "tensorboard = TB(log_dir=\"./logs/\" + MODEL_PREFIX + \"/{}\".format(time()), \n",
    "                          histogram_freq=0, write_graph=True, write_images=False, log_every=10)\n",
    "\n",
    "callbacks=[tensorboard, \n",
    "           EarlyStopping(patience=5, monitor='val_loss'),\n",
    "           ModelCheckpoint(filepath=MODELS_PATH + 'checkpoints/'+ MODEL_PREFIX + '_gen' + str(RUN_INDEX) + '.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                           monitor='val_loss', verbose=1, mode='auto', period=1), \n",
    "           ModelCheckpoint(filepath=MODELS_PATH + MODEL_PREFIX + '_gen'+str(RUN_INDEX)+'.hdf5', \n",
    "                           monitor='val_loss', verbose=1, mode='auto', period=1, save_best_only=True)]\n",
    "\n",
    "model.fit([X_data, tag_data], y_data, epochs=10, batch_size=1024, shuffle=True, \n",
    "          verbose=1, validation_split=0.2, callbacks=callbacks, sample_weight=weight_data)\n",
    "\n",
    "print(\"Total elapsed time: \", time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights(MODELS_PATH + 'checkpoints/'+ MODEL_PREFIX + '_gen' + str(RUN_INDEX)+'_epoch1.hdf5')\n",
    "model = load_model('./models/checkpoints/combined_jokes_quote_controlled_stacked_lstm_glove_gen1.08-8.66.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_categorical(model, tokenizer, seed_text, maxlen, probabilistic=False, exploration_factor=1.0, tag=0):\n",
    "    \n",
    "    reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "    seq = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    print(seq)\n",
    "    \n",
    "    while True:\n",
    "        encoded_seq = seq\n",
    "        if len(seq) > MAX_SEQ_LEN:\n",
    "            encoded_seq = encoded_seq[-1*MAX_SEQ_LEN:]\n",
    "            \n",
    "        #padded_seq = pad_sequences([encoded_seq], maxlen=MAX_SEQ_LEN, padding='pre')\n",
    "        padded_seq = np.array([seq])\n",
    "        tags = to_categorical(np.full((1, padded_seq[0].shape[0]), tag), TAG_SIZE)\n",
    "        y_prob = model.predict([padded_seq,tags])[0][-1].reshape(1,-1)#[3:].reshape(-1,1)\n",
    "        \n",
    "        if np.random.rand() <= exploration_factor:\n",
    "            probabilistic = True\n",
    "        else:\n",
    "            probabilistic = False\n",
    "            \n",
    "        if probabilistic:\n",
    "            y_class = np.argmax(np.random.multinomial(1,y_prob[0]/(np.sum(y_prob[0])+1e-5),1))\n",
    "        else:\n",
    "            y_class = y_prob.argmax(axis=-1)[0]\n",
    "        \n",
    "        if y_class == 0:\n",
    "            break\n",
    "        out_word = reverse_word_map[y_class]\n",
    "        seq.append(y_class)\n",
    "        if out_word == 'eos' or len(seq) > maxlen or out_word == 'sos':\n",
    "            break\n",
    "    \n",
    "    words = [reverse_word_map[idx] for idx in seq]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 873, 1182]\n",
      "sos yo mama so fat she had to drop her fist in the oven . she says \" i don't know , but i think i was going to get a little bit of a lighter . eos\n"
     ]
    }
   ],
   "source": [
    "joke = generate_categorical(model, tokenizer, \"sos yo mama\", maxlen=40, tag=0, exploration_factor=0.1)\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 873, 1182]\n",
      "sos yo mama is so expressive . she has always been the kind of guy that i love in my life , but i have a lot of friends , and i don't think she'd ever seen him . eos\n"
     ]
    }
   ],
   "source": [
    "joke = generate_categorical(model, tokenizer, \"sos yo mama\", maxlen=40, tag=1, exploration_factor=0.2)\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generate 10 random jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random = np.random.randint(0,len(sentences),100)\n",
    "random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 695, 162, 695, 47, 19, 23, 99, 1904, 503, 21]\n",
      "[1, 23, 24, 11, 42, 38, 11, 361, 325, 3349, 382]\n",
      "[1, 6, 1163, 1199]\n",
      "[1, 6, 24, 32, 111, 13, 239, 95]\n",
      "[1, 100, 732, 9]\n",
      "[1, 4798, 4991, 34, 3146, 221, 3, 485, 2610, 54]\n",
      "[1, 4767, 56, 459, 93, 5, 1778, 124, 37, 117]\n",
      "[1, 1698, 3]\n",
      "[1, 6, 1366, 1033, 4]\n",
      "[1, 23, 24, 11, 107, 5]\n",
      "[1, 31, 3589, 110, 6, 15, 4, 6763, 8, 65, 134, 65, 899]\n",
      "[1, 50, 24, 11]\n",
      "[1, 6, 106, 466, 72]\n",
      "[1, 6, 36, 13, 184]\n",
      "[1, 6, 269, 7, 265, 2050, 2013, 8, 89, 3]\n",
      "[1, 6, 79, 7, 64, 42]\n",
      "[1, 2571, 99, 998]\n",
      "[1, 569, 732, 9, 83]\n",
      "[1, 100, 4, 146, 125, 5, 3739]\n",
      "[1, 6, 56, 10768, 11, 8, 772, 1172, 12, 5, 10751]\n"
     ]
    }
   ],
   "source": [
    "joke_list = []\n",
    "for i in random[:20]:\n",
    "    sent = sentences[i]\n",
    "    seed_list = sent.split()\n",
    "    seed = seed_list[:int(len(seed_list)/3)]\n",
    "    joke = generate_categorical(model, tokenizer,' '.join(seed), maxlen=40, tag=0, exploration_factor=0.3)\n",
    "    joke_list.append((' '.join(seed),joke))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sos blonde joke blonde : \" what does idk stand for',\n",
       "  'sos blonde joke blonde : \" what does idk stand for ? \" \" a : \" little johnny , \" they said it was one of the few . eos'),\n",
       " ('sos what do you get when you cross hot chicks coming',\n",
       "  'sos what do you get when you cross hot chicks coming from a gay bar ? a : storage eos'),\n",
       " ('sos i bet cats',\n",
       "  \"sos i bet cats are when golfers have gender questions . they don't know how to argue with it . eos\"),\n",
       " ('sos i do not see my family life',\n",
       "  \"sos i do not see my family life . i don't know what i told them was , but i think they misunderstood me when i said i was pregnant . eos\"),\n",
       " (\"sos what's green and\",\n",
       "  \"sos what's green and smells like pork ? kermit the frog's finger and says - wow , i think you should have seen the coolest guy in fb . eos\"),\n",
       " ('sos edward snowden just joined twitter . almost immediately he',\n",
       "  'sos edward snowden just joined twitter . almost immediately he had no gaming . i was just a bit of a racist . eos'),\n",
       " ('sos gambling can turn into a dangerous two - way',\n",
       "  'sos gambling can turn into a dangerous two - way - to - stop - motion . eos'),\n",
       " ('sos weed .',\n",
       "  'sos weed . i was his mother and i was like the same way i forgot to take a picture of her gone . eos'),\n",
       " ('sos i accidentally wet the',\n",
       "  \"sos i accidentally wet the paper in the shower threedots threedots but i couldn't find it . eos\"),\n",
       " ('sos what do you call a',\n",
       "  'sos what do you call a black guy with no arms and no legs ? a pilot , you racist bastard . eos'),\n",
       " ('sos so confident am i in the intentions , as well as wisdom',\n",
       "  'sos so confident am i in the intentions , as well as wisdom , i have been a slow - down . eos'),\n",
       " ('sos how do you',\n",
       "  'sos how do you know when a blonde is pregnant ? when she starts her sentence with the exhibit . eos'),\n",
       " ('sos i always learn from',\n",
       "  'sos i always learn from my mistakes , but i can only deal with the ones that are going to be done . eos'),\n",
       " ('sos i like my women',\n",
       "  'sos i like my women like i like my coffee threedots ground up and in the freezer . eos'),\n",
       " ('sos i wanted to play professional hockey , man .',\n",
       "  \"sos i wanted to play professional hockey , man . i should've seen her face when she cup of coffee on the table . eos\"),\n",
       " ('sos i had to go get',\n",
       "  'sos i had to go get a better presidential candidate than trump figures . i think the government is still a little more like the internet except the making of a zen threedots it is a real crime . eos'),\n",
       " ('sos pc does anybody',\n",
       "  'sos pc does anybody know what the difference between a black guy and a pizza ? a pizza can feed a family of four . eos'),\n",
       " ('sos whats green and has',\n",
       "  'sos whats green and has wheels ? grass , i lied about the wheels . eos'),\n",
       " (\"sos what's the difference between a chickpea\",\n",
       "  \"sos what's the difference between a chickpea and a lentil ? i've never had a garbanzo bean on my own . eos\"),\n",
       " ('sos i can assure you , public service is a stimulating',\n",
       "  'sos i can assure you , public service is a stimulating , and a text from a mafia . eos')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sos blonde joke blonde : \" what does idk stand for ? \" \" a : \" little johnny , \" they said it was one of the few . eos\n",
      "sos what do you get when you cross hot chicks coming from a gay bar ? a : storage eos\n",
      "sos i bet cats are when golfers have gender questions . they don't know how to argue with it . eos\n",
      "sos i do not see my family life . i don't know what i told them was , but i think they misunderstood me when i said i was pregnant . eos\n",
      "sos what's green and smells like pork ? kermit the frog's finger and says - wow , i think you should have seen the coolest guy in fb . eos\n",
      "sos edward snowden just joined twitter . almost immediately he had no gaming . i was just a bit of a racist . eos\n",
      "sos gambling can turn into a dangerous two - way - to - stop - motion . eos\n",
      "sos weed . i was his mother and i was like the same way i forgot to take a picture of her gone . eos\n",
      "sos i accidentally wet the paper in the shower threedots threedots but i couldn't find it . eos\n",
      "sos what do you call a black guy with no arms and no legs ? a pilot , you racist bastard . eos\n",
      "sos so confident am i in the intentions , as well as wisdom , i have been a slow - down . eos\n",
      "sos how do you know when a blonde is pregnant ? when she starts her sentence with the exhibit . eos\n",
      "sos i always learn from my mistakes , but i can only deal with the ones that are going to be done . eos\n",
      "sos i like my women like i like my coffee threedots ground up and in the freezer . eos\n",
      "sos i wanted to play professional hockey , man . i should've seen her face when she cup of coffee on the table . eos\n",
      "sos i had to go get a better presidential candidate than trump figures . i think the government is still a little more like the internet except the making of a zen threedots it is a real crime . eos\n",
      "sos pc does anybody know what the difference between a black guy and a pizza ? a pizza can feed a family of four . eos\n",
      "sos whats green and has wheels ? grass , i lied about the wheels . eos\n",
      "sos what's the difference between a chickpea and a lentil ? i've never had a garbanzo bean on my own . eos\n",
      "sos i can assure you , public service is a stimulating , and a text from a mafia . eos\n"
     ]
    }
   ],
   "source": [
    "for f,s in joke_list:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
