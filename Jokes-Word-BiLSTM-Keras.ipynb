{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import importlib\n",
    "from library import data_preprocess as dp\n",
    "importlib.reload(dp)\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Embedding\n",
    "from keras import regularizers\n",
    "from keras.metrics import sparse_categorical_accuracy, sparse_categorical_crossentropy\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './datasets/jokes.pickle'\n",
    "VOCAB_PATH = './datasets/jokes_vocabulary.pickle'\n",
    "MODELS_PATH = './models/'\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 13\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 512\n",
    "DROPOUT_FACTOR = 0.333\n",
    "REGULARIZATION = 0.00001\n",
    "DEEPER_DIM = 256\n",
    "\n",
    "DATA_PERCENT = 0.1\n",
    "\n",
    "RUN_INDEX = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences =  96910\n",
      "[\"sos what gifts do squirrels exchange on valentine's day ? forget - me - nuts . eos\", \"sos i have no problem getting women into the sack threedots threedots it's getting the sack into the back of my van that's the problem . eos\"]\n",
      "Vocab size =  8922\n",
      "['sos', 'did', 'you', 'hear', 'about', 'the', 'new', 'corduroy', 'pillows', '?']\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_PATH, 'rb') as pickleFile:\n",
    "    sentences = pickle.load(pickleFile)\n",
    "\n",
    "with open(VOCAB_PATH, 'rb') as pickleFile:\n",
    "    vocab = pickle.load(pickleFile)\n",
    "    \n",
    "random.shuffle(sentences)\n",
    "\n",
    "print(\"Number of sentences = \", len(sentences))\n",
    "print(sentences[:2])\n",
    "print(\"Vocab size = \", len(vocab))\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 17, 3335, 20, 3858, 4805, 26, 1962, 104, 6, 749, 42, 22, 42, 468, 3, 2], [1, 7, 27, 62, 469, 199, 132, 72, 5, 1904, 15, 15, 57, 199, 5, 1904, 72, 5, 131, 19, 13, 2747, 156, 5, 469, 3, 2], [1, 17, 20, 9, 66, 4, 222, 195, 1254, 26, 4, 430, 6, 1701, 2], [1, 292, 2885, 17, 95, 202, 65, 20, 30, 4, 2150, 2], [1, 4019, 997, 130, 72, 4, 97, 134, 5, 315, 18, 4928, 1726, 15, 2229, 5, 82, 15, 2]]\n",
      "8923\n"
     ]
    }
   ],
   "source": [
    "# tokenize data\n",
    "num_words = len(vocab)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, filters='', lower=True, split=' ', \n",
    "                      char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "assert num_words == len(tokenizer.word_index)\n",
    "\n",
    "encoded_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "print(encoded_sentences[:5])\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open(MODELS_PATH + 'jokes_tokenizer_' + str(RUN_INDEX) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training data size =  833131\n",
      "Max seq len =  13\n",
      "(833131, 13)\n",
      "[[   1   17 3335   20 3858 4805   26 1962  104    6  749   42   22]\n",
      " [  17 3335   20 3858 4805   26 1962  104    6  749   42   22   42]]\n",
      "(833131, 1)\n",
      "[[ 42]\n",
      " [468]]\n"
     ]
    }
   ],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "for sentence in encoded_sentences:\n",
    "    l = len(sentence)\n",
    "    sliding_window_length = min(l-3, MAX_SEQUENCE_LENGTH)\n",
    "    step_size = 1\n",
    "    for i in range(0, l - sliding_window_length, step_size):\n",
    "        X_data.append(sentence[i:i+sliding_window_length])\n",
    "        y_data.append(sentence[i+sliding_window_length])\n",
    "        \n",
    "print(\"Total training data size = \", len(X_data))\n",
    "MAX_SEQ_LEN = max([len(seq) for seq in X_data])\n",
    "print(\"Max seq len = \", MAX_SEQ_LEN)\n",
    "X_data = pad_sequences(X_data, maxlen=MAX_SEQ_LEN, padding='pre')\n",
    "y_data = np.array(y_data).reshape(-1,1)\n",
    "print(X_data.shape)\n",
    "print(X_data[:2])\n",
    "print(y_data.shape)\n",
    "print(y_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "def BiLSTM(vocab_size, embedding_dim, hidden_dim, deeper_dim, max_seq_len, \n",
    "           dropout_factor=0.5, regularization=0.00001):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=max_seq_len, \n",
    "                        mask_zero=True, embeddings_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Bidirectional(LSTM(hidden_dim, \n",
    "                                 activation='tanh',\n",
    "                                 kernel_regularizer=regularizers.l2(regularization),\n",
    "                                 recurrent_regularizer=regularizers.l2(regularization), unroll=True#, return_sequences = True\n",
    "                                )))\n",
    "    model.add(Dropout(dropout_factor))\n",
    "    model.add(Dense(units=deeper_dim, activation='elu', \n",
    "              kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(dropout_factor))\n",
    "    model.add(Dense(units=vocab_size, activation='softmax', \n",
    "              kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', \n",
    "                  metrics=[sparse_categorical_crossentropy, sparse_categorical_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 13, 128)           1142144   \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 1024)              2625536   \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8923)              2293211   \n",
      "=================================================================\n",
      "Total params: 6,323,291\n",
      "Trainable params: 6,323,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTM(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, deeper_dim=DEEPER_DIM,\n",
    "              max_seq_len=MAX_SEQ_LEN, dropout_factor=DROPOUT_FACTOR, regularization=REGULARIZATION)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TB(TensorBoard):\n",
    "    def __init__(self, log_every=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.log_every = log_every\n",
    "        self.counter = 0\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.counter+=1\n",
    "        if self.counter%self.log_every==0:\n",
    "            for name, value in logs.items():\n",
    "                if name in ['batch', 'size']:\n",
    "                    continue\n",
    "                summary = tf.Summary()\n",
    "                summary_value = summary.value.add()\n",
    "                summary_value.simple_value = value.item()\n",
    "                summary_value.tag = name\n",
    "                self.writer.add_summary(summary, self.counter)\n",
    "            self.writer.flush()\n",
    "        \n",
    "        super().on_batch_end(batch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 666504 samples, validate on 166627 samples\n",
      "Epoch 1/10\n",
      "194560/666504 [=======>......................] - ETA: 1:47 - loss: 3.8640 - sparse_categorical_crossentropy: 3.7225 - sparse_categorical_accuracy: 0.3346"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "tensorboard = TB(log_dir=\"./logs/jokes_bilstm/{}\".format(time()), \n",
    "                          histogram_freq=0, write_graph=True, write_images=False, log_every=10)\n",
    "\n",
    "callbacks=[tensorboard, \n",
    "           EarlyStopping(patience=5, monitor='val_loss'),\n",
    "           ModelCheckpoint(filepath=MODELS_PATH + 'checkpoints/jokes_bilstm_gen'+str(RUN_INDEX)+'.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                           monitor='val_loss', verbose=1, mode='auto', period=1), \n",
    "           ModelCheckpoint(filepath=MODELS_PATH + 'jokes_bilstm_gen'+str(RUN_INDEX)+'.hdf5', \n",
    "                           monitor='val_loss', verbose=1, mode='auto', period=1, save_best_only=True)]\n",
    "\n",
    "model.fit(X_data, y_data, epochs=10, batch_size=2048, shuffle=True, verbose=1, validation_split=0.2, \n",
    "          callbacks=callbacks)\n",
    "\n",
    "print(\"Total elapsed time: \", time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate(model, tokenizer, seed_text, maxlen):\n",
    "    \n",
    "    reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "    seq = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    print(seq)\n",
    "    \n",
    "    while True:\n",
    "        if len(seq) > MAX_SEQ_LEN:\n",
    "            encoded_seq = seq[-1*MAX_SEQ_LEN:]\n",
    "        else:\n",
    "            encoded_seq = seq\n",
    "        padded_seq = pad_sequences([encoded_seq], maxlen=MAX_SEQ_LEN, padding='pre')\n",
    "        #padded_seq = np.array([seq])\n",
    "        y_prob = model.predict(padded_seq)\n",
    "        y_class = y_prob.argmax(axis=-1)[0]\n",
    "        if y_class == 0:\n",
    "            break\n",
    "        out_word = reverse_word_map[y_class]\n",
    "        seq.append(y_class)\n",
    "        if out_word == 'eos' or len(seq) > maxlen:\n",
    "            break\n",
    "    \n",
    "    words = [reverse_word_map[idx] for idx in seq]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 7, 84, 8, 258]\n",
      "sos i had to use a lot of money . plagiarism . i don't know what i have to be . eos\n"
     ]
    }
   ],
   "source": [
    "joke = generate(model, tokenizer, \"sos i had to use\", maxlen=40)\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sos hello', 'hello ,', \", i'm\", \"i'm a\", 'a dinosaur', 'dinosaur .', '. eos']\n"
     ]
    }
   ],
   "source": [
    "def bigrams_list(sentence):\n",
    "    words = sentence.split(' ')\n",
    "    bigrams = []\n",
    "    for i in range(0, len(words)-1):\n",
    "        bigrams.append(words[i]+' '+words[i+1])\n",
    "    return bigrams\n",
    "\n",
    "print(bigrams_list(\"sos hello , i'm a dinosaur . eos\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sos they', 'they say', 'say a', \"a woman's\", \"woman's work\", 'work is', 'is never', 'never done', 'done threedots', 'threedots maybe', \"maybe that's\", \"that's why\", 'why they', 'they get', 'get paid', 'paid less', 'less than', 'than men', 'men .', '. eos'], ['sos going', 'going to', 'to mcdonalds', 'mcdonalds for', 'for a', 'a salad', 'salad is', 'is like', 'like going', 'going to', 'to a', 'a hooker', 'hooker for', 'for a', 'a hug', 'hug .', '. eos']]\n"
     ]
    }
   ],
   "source": [
    "sentence_bigrams = [bigrams_list(s) for s in sentences]\n",
    "print(sentence_bigrams[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    temp = set(lst2)\n",
    "    lst3 = [value for value in lst1 if value in temp]\n",
    "    return lst3\n",
    "\n",
    "def similarity_score(lst1, lst2):\n",
    "    intersection_len = len(intersection(lst1, lst2))\n",
    "    return (1.0*intersection_len)/len(lst1)#+len(lst2)-intersection_len)\n",
    " \n",
    "def print_closest_sentences(sentence, sentence_bigrams, top_k=3):\n",
    "    bigrams = bigrams_list(sentence)\n",
    "    scores = np.array([similarity_score(bigrams, sbigrams)\n",
    "                       for sbigrams in sentence_bigrams])\n",
    "    top_k_indices = scores.argsort()[-1*top_k:][::-1]\n",
    "    top_k_scores = scores[top_k_indices]\n",
    "    for k in range(top_k):\n",
    "        print(top_k_scores[k], \" -> \", sentences[top_k_indices[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5  ->  sos i had to use my glasses when playing tennis . because its a no contact sport . eos\n",
      "0.4  ->  sos i had to stop drinking . i kept getting that thing where you feel sick and your head hurts threedots depression . eos\n",
      "0.4  ->  sos i found a stray cat today . sadly , my dad is allergic to them so i had to put him down . at least i still have the cat for comfort . eos\n",
      "0.4  ->  sos ran out of toilet paper , so i had to use leaves . just kidding , but my son learned a big lesson about leaving his clothes in the bathroom . eos\n",
      "0.4  ->  sos i used to date a girl with a lazy eye . i had to break up with her . she was seeing somebody on the side . eos\n",
      "0.4  ->  sos i recently broke up with my long term japanese girlfriend threedots she didn't seem to understand so i had to drop the bomb on her twice . eos\n",
      "0.4  ->  sos i had a vasectomy today , and my wife keeps asking how i feel threedots i've had to tell her over and over that it's not that bad , and that i don't notice much of a vas deferens . eos\n",
      "0.4  ->  sos i was bored at work yesterday , so i gave a colleague a clock and told him to give it to someone else . i had to do something to pass the time . eos\n",
      "0.4  ->  sos i had to fire my receptionist today . there was just no connection . eos\n",
      "0.4  ->  sos i had to put my dog down today . i'd been carrying her for a while . eos\n"
     ]
    }
   ],
   "source": [
    "print_closest_sentences(joke, sentence_bigrams, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 17, 20, 9, 66]\n",
      "sos what do you call ? a stick up a cliff . a woman . eos\n",
      "0.5333333333333333  ->  sos i was told that exercise helps with your decision making . it's true . after going to the gym earlier i've decided i'm never going again . eos\n",
      "0.5333333333333333  ->  sos what do toilet paper and the star ship enterprise have in common they both circle uranus and battle klingons eos\n",
      "0.4666666666666667  ->  sos did you hear about the white guy who got pulled over ? me neither . eos\n",
      "0.4666666666666667  ->  sos i wasn't dropped as a baby , but i've been making up for it ever since . eos\n",
      "0.4666666666666667  ->  sos why are native americans the best strippers ? because when they dance they make it rain . eos\n",
      "0.4666666666666667  ->  sos what did the eskimo children sing when their principal was leaving ? freeze a jolly good fellow . eos\n",
      "0.4666666666666667  ->  sos i seriously hate it when a couple starts having an argument in front of you . they could have least waited until i got dressed and left . eos\n",
      "0.4666666666666667  ->  sos by the time you finish reading this tweet , you will be slightly closer to death than you were before . i hope it was worth it . eos\n",
      "0.4666666666666667  ->  sos i hate when a girl says the wrong name during sex they know my name isnt someone help eos\n",
      "0.4666666666666667  ->  sos what do you do you with an elephant with three balls ? walk him and pitch to the rhino . eos\n"
     ]
    }
   ],
   "source": [
    "joke = generate(model, tokenizer, \"sos what do you call\", maxlen=40)\n",
    "print(joke)\n",
    "print_closest_sentences(joke, sentence_bigrams, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sos a woman was arrested when her boyfriend's body was found in a freezer in their living room . who the hell puts a freezer in the living room ? eos\", 'sos what does heroin make you feel like ? more heroin . eos', \"sos why couldn't the physicist understand how boats work ? he thought nothing could possibly travel faster than sea . eos\", \"sos at what age do you tell a highway it's adopted ? eos\", \"sos russians dolls . they're so full of themselves eos\", \"sos how many chocolate bunnies can you put into an empty easter basket ? one . after that the basket won't be empty . eos\", \"sos nurse pops her head into the doctor's office threedots nurse : ' doctor , there's an invisible man in the waiting room . ' doctor : ' tell him i can't see him . ' eos\", 'sos what kind of file makes a hole bigger ? a pedophile eos', \"sos what is a paranoid man's favorite food ? who wants to know ? eos\", \"sos friends invited me to a meteor shower party , but i couldn't make it . they were crushed . eos\"]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 5, 76, 74, 167, 859]\n",
      "sos what's the difference between being hungry ? a stick in a tank and a busty crustacean . eos\n",
      "0.5  ->  sos why couldn't moses adopt a kitten from the animal shelter ? because the shelter was non prophet . eos\n",
      "0.5  ->  sos men : don't lie to your woman , she'll catch you . don't tell her the truth , she'll be pissed . just pray for a brick to fall on your head . eos\n",
      "0.5  ->  sos hockey : because running on knives makes sense . eos\n",
      "0.5  ->  sos a riddle : what's the only hole that i can't put my dick in ? answer : a donut hole ! eos\n",
      "0.5  ->  sos what tea is hardest to swallow ? reality eos\n",
      "0.5  ->  sos what happens when you don't pay your exorcist ? threedots you get repossessed . eos\n",
      "0.5  ->  sos \" you suck . \" \" no , you suck . \" \" really , you suck . \" \" please , you suck . \" \" you suck , i insist . \" - polite vampires . eos\n",
      "0.5  ->  sos why are pot heads always so condescending ? they always think they're higher then others eos\n",
      "0.5  ->  sos i know a good dad joke . but i have to wait for dad to come back to tell . eos\n",
      "0.5  ->  sos why did abe lincoln get released from prison ? because he's in a cent eos\n"
     ]
    }
   ],
   "source": [
    "joke = generate(model, tokenizer, \"sos what's the difference between being hungry\", maxlen=40)\n",
    "print(joke)\n",
    "print_closest_sentences(joke, sentence_bigrams, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =  load_model('models/checkpoints/jokes_bilstm_gen2.08-4.39.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 107, 1837]\n",
      "sos a guy finds up . period is it . eos\n",
      "0.4  ->  sos what did the baby milk say to his older sister ? you're spoiled ! eos\n",
      "0.4  ->  sos girl are you a dishwasher ? because i would like to fill you with my dirty load in the evening , turn you on , and fall asleep before you finish eos\n",
      "0.4  ->  sos if a shark attacks you , do not punch him in the nose . be the bigger person and just ignore him . eos\n",
      "0.3  ->  sos when you have the opportunity to become a bigger person , take it because cake is delicious . eos\n",
      "0.3  ->  sos what's the difference between hitler and michael phelps ? michael phelps could finish a race . eos\n",
      "0.3  ->  sos the difference between \" like \" \" love \" and \" in love \" is the same as the difference between \" for now \" \" for a while \" and \" forever \" eos\n",
      "0.3  ->  sos what do engineers use for birth control ? personality . eos\n",
      "0.3  ->  sos what's the only thing working out at the gym ? the business plan . eos\n",
      "0.3  ->  sos my wife thinks i'm cheating on her with our babysitter threedots i think she's just bitter because she's never been able to have kids threedots eos\n",
      "0.3  ->  sos knock knock who's there ? to to who ? to whom . eos\n"
     ]
    }
   ],
   "source": [
    "joke = generate(model, tokenizer, \"sos a guy finds\", maxlen=40)\n",
    "print(joke)\n",
    "print_closest_sentences(joke, sentence_bigrams, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
