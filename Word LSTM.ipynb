{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wget\n",
    "import pickle\n",
    "import collections\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = 'vocabulary.csv'\n",
    "cleaned_data_file = 'cleaned_jokes.csv'\n",
    "seq_length = 30\n",
    "sequences_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = wget.download('https://github.com/amoudgl/short-jokes-dataset/raw/master/shortjokes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shortjokes (1).csv\n"
     ]
    }
   ],
   "source": [
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ID\",\"Joke\"\n",
      "1,\"[me narrating a documentary about narrators] \"\"I can't hear what they're saying cuz I'm talking\"\"\"\n",
      "2,\"Telling my daughter garlic is good for you. Good immune system and keeps pests away.Ticks, mosquitos, vampires... men.\"\n",
      "3,\"I've been going through a really rough period at work this week It's my own fault for swapping my tampax for sand paper.\"\n",
      "4,\"If I could have dinner with anyone, dead or alive... ...I would choose alive. -B.J. Novak-\"\n",
      "5,\"Two guys walk into a bar. The third guy ducks.\"\n",
      "6,\"Why can't Barbie get pregnant? Because Ken comes in a different box. Heyooooooo\"\n",
      "7,\"Why was the musician arrested? He got in treble.\"\n",
      "8,\"Did you hear about the guy who blew his entire lottery winnings on a limousine? He had nothing left to chauffeur it.\"\n",
      "9,\"What do you do if a bird shits on your car? Don't ask her out again.\"\n"
     ]
    }
   ],
   "source": [
    "joke_text = []\n",
    "joke_id = []\n",
    "num_jokes = 0\n",
    "with open(filename,\"r\") as fip:\n",
    "    jokes = fip.read().split(\"\\n\")\n",
    "    for j in jokes[:10]:\n",
    "        print(j)\n",
    "    num_jokes = len(jokes)\n",
    "    for i,joke in enumerate(jokes):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        temp = joke.split(',')\n",
    "        if len(temp) < 2:\n",
    "            continue\n",
    "        joke_text.append(temp[1])\n",
    "        joke_id.append(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231659"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"[me narrating a documentary about narrators] \"\"I can\\'t hear what they\\'re saying cuz I\\'m talking\"\"\"',\n",
       " '\"Telling my daughter garlic is good for you. Good immune system and keeps pests away.Ticks',\n",
       " '\"I\\'ve been going through a really rough period at work this week It\\'s my own fault for swapping my tampax for sand paper.\"',\n",
       " '\"If I could have dinner with anyone',\n",
       " '\"Two guys walk into a bar. The third guy ducks.\"',\n",
       " '\"Why can\\'t Barbie get pregnant? Because Ken comes in a different box. Heyooooooo\"',\n",
       " '\"Why was the musician arrested? He got in treble.\"',\n",
       " '\"Did you hear about the guy who blew his entire lottery winnings on a limousine? He had nothing left to chauffeur it.\"',\n",
       " '\"What do you do if a bird shits on your car? Don\\'t ask her out again.\"',\n",
       " '\"He was a real gentlemen and always opened the fridge door for me\"']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(raw_data):\n",
    "    processed_data = []\n",
    "    for d in raw_data:\n",
    "        d = d.strip().lower()\n",
    "        d = d.replace('.',' EOS ')\n",
    "        d  = [x for x in d if (ord(x) >= ord('a') and ord(x) <= ord('z')) or (ord(x) >= ord('A') and ord(x) <= ord('Z')) or (ord(x) == ord(' '))]\n",
    "        d = ''.join(d)\n",
    "        d = ' '.join(d.split())\n",
    "        processed_data.append(d)\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_text_processed = cleanData(joke_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['me narrating a documentary about narrators i cant hear what theyre saying cuz im talking',\n",
       " 'telling my daughter garlic is good for you EOS good immune system and keeps pests away EOS ticks',\n",
       " 'ive been going through a really rough period at work this week its my own fault for swapping my tampax for sand paper EOS',\n",
       " 'if i could have dinner with anyone',\n",
       " 'two guys walk into a bar EOS the third guy ducks EOS',\n",
       " 'why cant barbie get pregnant because ken comes in a different box EOS heyooooooo',\n",
       " 'why was the musician arrested he got in treble EOS',\n",
       " 'did you hear about the guy who blew his entire lottery winnings on a limousine he had nothing left to chauffeur it EOS',\n",
       " 'what do you do if a bird shits on your car dont ask her out again EOS',\n",
       " 'he was a real gentlemen and always opened the fridge door for me']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_text_processed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD EOJ (End of joke)\n",
    "for i in range(len(joke_text_processed)):\n",
    "    joke_text_processed[i] = joke_text_processed[i]+\" EOJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cleaned_data_file,\"wb\") as fop:\n",
    "    pickle.dump(joke_text_processed,fop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['me narrating a documentary about narrators i cant hear what theyre saying cuz im talking EOJ',\n",
       " 'telling my daughter garlic is good for you EOS good immune system and keeps pests away EOS ticks EOJ',\n",
       " 'ive been going through a really rough period at work this week its my own fault for swapping my tampax for sand paper EOS EOJ',\n",
       " 'if i could have dinner with anyone EOJ',\n",
       " 'two guys walk into a bar EOS the third guy ducks EOS EOJ',\n",
       " 'why cant barbie get pregnant because ken comes in a different box EOS heyooooooo EOJ',\n",
       " 'why was the musician arrested he got in treble EOS EOJ',\n",
       " 'did you hear about the guy who blew his entire lottery winnings on a limousine he had nothing left to chauffeur it EOS EOJ',\n",
       " 'what do you do if a bird shits on your car dont ask her out again EOS EOJ',\n",
       " 'he was a real gentlemen and always opened the fridge door for me EOJ']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_text_processed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23165.7\n"
     ]
    }
   ],
   "source": [
    "#percentage\n",
    "percenatge = 0.1\n",
    "joke_text_processed_reduced = joke_text_processed[:int(len(joke_text_processed)*percenatge)]\n",
    "joke_text_id_reduced = joke_id[:int(len(joke_id)*percenatge)]\n",
    "assert len(joke_text_processed_reduced) == len(joke_text_id_reduced)\n",
    "print(len(joke_text_processed)*percenatge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23165"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joke_text_processed_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_words_list = []\n",
    "for joke in joke_text_processed_reduced:\n",
    "    for word in joke.split():\n",
    "        joke_words_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379409"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Num words\n",
    "len(joke_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20650"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Num uniqe words\n",
    "len(set(joke_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  20650\n"
     ]
    }
   ],
   "source": [
    "# count the number of words\n",
    "wordlist = joke_words_list\n",
    "word_counts = collections.Counter(joke_words_list)\n",
    "\n",
    "# Mapping from index to word : that's the vocabulary\n",
    "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "\n",
    "# Mapping from word to index\n",
    "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "words = [x[0] for x in word_counts.most_common()]\n",
    "\n",
    "#size of the vocabulary\n",
    "vocab_size = len(words)\n",
    "print(\"vocab size: \", vocab_size)\n",
    "\n",
    "#save the words and vocabulary\n",
    "with open(os.path.join(vocab_file), 'wb') as f:\n",
    "    pickle.dump((words, vocab, vocabulary_inv), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 379379\n"
     ]
    }
   ],
   "source": [
    "#create sequences\n",
    "sequences = []\n",
    "next_words = []\n",
    "for i in range(0, len(wordlist) - seq_length, sequences_step):\n",
    "    sequences.append(wordlist[i: i + seq_length])\n",
    "    next_words.append(wordlist[i + seq_length])\n",
    "\n",
    "print('nb sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
